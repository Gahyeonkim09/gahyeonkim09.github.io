<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Gahyeon Kim | Portfolio</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root {
      --bg: #f7f7fb; --card: #ffffff; --text: #222; --muted: #6b7280;
      --accent: #0f62fe; --border: #e5e7eb; --shadow: 0 10px 30px rgba(0,0,0,.07);
    }
    * { box-sizing: border-box; }
    html { scroll-behavior: smooth; }
    body { margin: 0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial; background: var(--bg); color: var(--text); line-height: 1.6; }
    header { padding: 2.5rem 1rem; text-align: center; background: #111827; color: #fff; }
    header h1 { margin: 0; font-size: 2rem; }
    header p { margin: .4rem 0 0; color: #cbd5e1; }
    main { max-width: 960px; margin: 0 auto; padding: 2rem 1rem 3rem; }
    section { background: var(--card); border: 1px solid var(--border); border-radius: 16px; padding: 1.25rem 1rem; margin-top: 1rem; }
    h2 { margin: 0 0 .75rem; font-size: 1.15rem; }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }
    ul { margin: .25rem 0 0; padding-left: 1.2rem; }
    li { margin: .35rem 0; }
    .subtle { color: var(--muted); }
    .grid-2 { display: grid; gap: 1rem; grid-template-columns: 1fr; }
    @media (min-width: 860px) { .grid-2 { grid-template-columns: 1fr 1fr; } }
    .pill { display: inline-block; padding: .3rem .6rem; border-radius: 999px; background: #eef2ff; color: #3730a3; font-size: .85rem; border: 1px solid #e0e7ff; }
    .callout { border-left: 4px solid #dbeafe; background: #f8fbff; padding: .8rem 1rem; border-radius: 10px; }
    .pub-international .callout + .callout { margin-top: 1rem; } /* êµ­ì œ ë…¼ë¬¸ ê°„ê²© */
    .pub-links { margin-top: .4rem; font-size: .95rem; }
    .pub-links a { margin-right: .8rem; }
    .edu-item { margin-bottom: .9rem; }
    .role { font-weight: 600; }
    .where { color: var(--muted); }
    .dash { color: var(--muted); padding: 0 .25rem; }

    /* ===== Profile block (Intro ìœ„) ===== */
    .profile {
      display: flex; align-items: center; justify-content: center; flex-wrap: wrap; gap: 1rem;
      background: var(--card); border: 1px solid var(--border); border-radius: 16px;
      padding: 1.2rem 1rem; margin-top: 1rem;
    }
    .avatar {
      width: 120px; height: 120px; border-radius: 50%; object-fit: cover;
      border: 2px solid var(--border); box-shadow: var(--shadow);
    }
    .profile-cta { display: flex; align-items: center; gap: .75rem; flex-wrap: wrap; justify-content: center; }
    .btn {
      display: inline-flex; align-items: center; gap: .5rem;
      padding: .6rem 1rem; border-radius: 999px; border: none; cursor: pointer;
      background: var(--accent); color: #fff; font-weight: 600; text-decoration: none;
      box-shadow: 0 6px 16px rgba(15,98,254,.18);
    }
    .btn:hover { filter: brightness(0.96); }
    .btn:focus { outline: 3px solid rgba(15,98,254,.35); outline-offset: 2px; }

    /* ===== Floating TOC (ì‘ê²Œ) ===== */
    .toc {
      position: fixed; right: 16px; top: 84px;
      width: 200px; max-height: 68vh; overflow: auto;
      background: var(--card); border: 1px solid var(--border); border-radius: 12px;
      box-shadow: var(--shadow); padding: .6rem .6rem; font-size: .9rem;
    }
    .toc h3 { margin: 0 0 .3rem; font-size: .92rem; }
    .toc a { display: block; padding: .25rem .4rem; border-radius: 8px; color: var(--text); text-decoration: none; border: 1px solid transparent; }
    .toc a:hover { background: #f3f4f6; border-color: #e5e7eb; }
    .toc a.active { background: #eef2ff; border-color: #e0e7ff; color: #3730a3; }
    .toc small { display:block; color: var(--muted); margin-bottom: .25rem; font-size: .8rem; }

    .toc-toggle {
      position: fixed; right: 12px; bottom: 12px; z-index: 99;
      background: #111827; color: #fff; border: none; border-radius: 999px;
      padding: .6rem .9rem; box-shadow: var(--shadow); cursor: pointer; font-size: .95rem;
    }
    @media (max-width: 1100px) {
      .toc { display: none; }
      .toc.open { display: block; right: 12px; bottom: 64px; top: auto; width: min(76vw, 280px); }
      .toc small { display: none; }
      .toc-toggle { display: inline-flex; }
    }
    @media (min-width: 1101px) {
      .toc-toggle { display: none; }
      main { padding-right: 240px; } /* ì¤„ì¸ TOC í­ì— ë§ì¶° ì—¬ë°±ë„ ì¶•ì†Œ */
    }

    /* Footer ì¤‘ì•™ ì •ë ¬ */
    footer { max-width: 960px; margin: 1.5rem auto 3rem; padding: 0 1rem; color: var(--muted); font-size: .92rem; text-align: center; }
    footer p { margin: .25rem 0; }
    footer em { font-style: italic; }

    /* Toggle(Accordion) for Accomplishments */
    details.accordion { margin: .5rem 0; border: 1px solid var(--border); border-radius: 12px; background: #fafafa; padding: .25rem .5rem .5rem; }
    details.accordion[open] { background: #f0f7ff; border-color: #dbeafe; }
    details.accordion > summary { list-style: none; cursor: pointer; padding: .5rem; border-radius: 10px; font-weight: 600; display: flex; align-items: center; gap: .5rem; outline: none; }
    details.accordion > summary::-webkit-details-marker { display: none; }
    details.accordion > summary::before { content: "â–¸"; font-size: .9rem; transition: transform .2s ease; color: #374151; }
    details.accordion[open] > summary::before { transform: rotate(90deg); }
    details.accordion .inner { padding: .25rem .75rem .25rem 1.4rem; }
    details.accordion .inner ul { margin-top: .35rem; }
  </style>
</head>
<body>
  <header>
    <h1>ğŸ‘©â€ğŸ’» Gahyeon (MarÃ­a) Kim</h1>
    <p>Computer Vision Â· Multimodal AI Â· Prompt Learning</p>
  </header>

  <!-- Floating TOC (smaller) -->
  <nav class="toc" id="toc">
    <h3>Site Map</h3>
    <small>Jump to section</small>
    <a href="#intro">Introduction</a>
    <a href="#personal-info">Personal Information</a>
    <a href="#research-interest">Research Interests</a>
    <a href="#education">Education</a>
    <a href="#publications">Publications</a>
    <a href="#research-experiences">Research Experiences</a>
    <a href="#services">Academic Services</a>
    <a href="#trainings">Trainings & Experiences</a>
    <a href="#projects">Projects & Grants</a>
    <a href="#awards">Awards</a>
    <a href="#languages">Languages</a>
    <a href="#skills">Skills</a>
    <a href="#free-time">Free time interests</a>
  </nav>
  <button class="toc-toggle" aria-expanded="false" aria-controls="toc">â˜° Map</button>

  <main>
    <!-- Profile block (image + CV) -->
    <section class="profile" aria-label="Profile">
      <img class="avatar" src="images/profile.jpg" alt="Portrait of Gahyeon Kim" loading="lazy" />
      <div class="profile-cta">
        <a class="btn" href="cv.pdf" download>
          â¬‡ï¸ Download CV
        </a>
      </div>
    </section>

    <!-- Intro -->
    <section id="intro">
      <h2>ğŸ‘‹ Introduction</h2>
      <p>
        Hello, I am <b>Gahyeon (MarÃ­a) Kim</b>, based in Anyang (Seoul metropolitan area), South Korea.
        As a computer vision specialist, I focus on prompt learning using features from pre-trained language and vision models for various downstream tasks.
      </p>
      <p>
        Specializing in multi-modal learning and computer vision, I develop data-efficient models using prompt learning and pre-trained LLMs and VLMs to improve generalization on complex data.
        Recently, I explored modality-free learning, training models with web-crawled physics simulator images via text-based interfaces.
      </p>
      <p>
        Passionate about cross-disciplinary research, I tackle cutting-edge AI challenges in multi-modal learning and cross-domain adaptation, aiming to push the boundaries of AI perception and reasoning.
      </p>
    </section>

    <!-- Personal Info + Research Interests -->
    <div class="grid-2">
      <section id="personal-info">
        <h2>â˜ï¸ Personal Information</h2>
        <ul>
          <li>ğŸ“§ Email: <a href="mailto:gahyeon@kentech.ac.kr">gahyeon@kentech.ac.kr</a></li>
          <li>ğŸ‘¾ GitHub: <a href="https://github.com/Gahyeonkim09" target="_blank">github.com/Gahyeonkim09</a></li>
          <li>ğŸ“¥ LinkedIn: <a href="https://www.linkedin.com/in/gahyeon-kim-a86710241/" target="_blank">linkedin.com/in/gahyeon-kim-a86710241</a></li>
          <li>ğŸ“š Google Scholar: <a href="https://scholar.google.com/citations?user=7p0Fd-oAAAAJ&hl=en" target="_blank">Google Scholar</a></li>
        </ul>
      </section>

      <section id="research-interest">
        <h2>ğŸ” Research Interests</h2>
        <p>
          Deep Learning, Computer Vision, Natural Language Processing, Multi-modal Learning,
          Large Language Models, Vision-Language Models, Prompt Learning, Modality-free Learning,
          Zero-shot &amp; Few-shot Learning
        </p>
      </section>
    </div>

    <!-- Education -->
    <section id="education">
      <h2>ğŸ“ Education</h2>

      <div class="edu-item">
        <div><b>M.S., Energy AI Track, Energy Engineering</b></div>
        <div><a href="https://kentech.ac.kr/main.do" target="_blank">Korea Institute of Energy Technology</a>
          <span class="dash">|</span> Mar 2023 â€“ Feb 2025</div>
        <div class="subtle">(G.P.A. 3.80/4.3)</div>
        <div class="subtle"><em>Advisor: Prof. <a href="https://view.kentech.ac.kr/prof" target="_blank">Seokju Lee</a></em></div>
      </div>

      <div class="edu-item">
        <div><b>B.S., Applied Physics</b></div>
        <div><a href="https://www.hanyang.ac.kr/web/eng/home" target="_blank">Hanyang University ERICA</a>
          <span class="dash">|</span> Mar 2019 â€“ Feb 2023</div>
        <div class="subtle">(G.P.A. 3.86/4.5) Â· Cum Laude</div>
        <div class="subtle"><em>Advisor: Prof. <a href="http://csg.hanyang.ac.kr/" target="_blank">Seungwoo Son</a></em></div>
      </div>
    </section>

    <!-- Publications -->
    <section id="publications">
      <h2>ğŸ“ Publications</h2>

      <h3 class="subtle">International</h3>
      <div class="pub-international">
        <div class="callout">
          <span class="pill">2025 Â· Under Review</span>
          <p><b>KIM, Gahyeon</b>; KIM, Sohee; LEE, Seokju.
            <b>Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models,</b> <i>Pattern Recognition</i>, 2025.</p>
        </div>

        <div class="callout">
          <span class="pill">2024</span>
          <p><b>KIM, Gahyeon</b>; KIM, Sohee; LEE, Seokju.
            <b>AAPL: Adding Attributes to Prompt Learning for Vision-Language Models,</b>
            <i>CVPR Workshops</i>, 2024, pp. 1572â€“1582.</p>
          <div class="pub-links">
            <a href="https://arxiv.org/abs/2404.16804" target="_blank">arXiv</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2024W/PV/papers/Kim_AAPL_Adding_Attributes_to_Prompt_Learning_for_Vision-Language_Models_CVPRW_2024_paper.pdf" target="_blank">CVF Open Access</a>
            <a href="https://github.com/Gahyeonkim09/AAPL" target="_blank">GitHub</a>
          </div>
        </div>
      </div>

      <h3 class="subtle" style="margin-top:1rem;">Domestic (Korean)</h3>
      <div class="callout">
        <span class="pill">2024</span>
        <p><b>ê±°ëŒ€ ì‹œê°-ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì´ë¯¸ì§€ ì¦ê°•ì„ í™œìš©í•œ í”„ë¡¬í”„íŠ¸ í•™ìŠµ</b>,
          <i>The 36th Workshop on Image Processing and Image Understanding (IPIU)</i>, Jan 2024.</p>
        <div class="pub-links">
          <a href="http://ipiu.or.kr/?act=board&bbs_code=IPIU2024_papers&bbs_mode=view&bbs_seq=61" target="_blank">Paper (P1-106)</a>
        </div>
      </div>
    </section>

    <!-- Research Experiences -->
    <section id="research-experiences">
      <h2>ğŸ’» Research Experiences</h2>

      <div class="edu-item">
        <div class="role">Postgraduate Researcher (M.S.)</div>
        <div class="where"><a href="https://etri-visualintelligence.github.io/" target="_blank">ETRI Visual Intelligence Lab</a>, Korea
          <span class="dash">|</span> Sep 2025 â€“ present</div>
      </div>

      <div class="edu-item">
        <div class="role">Postgraduate Researcher (M.S.)</div>
        <div class="where"><a href="https://view.kentech.ac.kr/" target="_blank">VIEW LAB (Visual Intelligence &amp; Energy Wise Lab)</a>, KENTECH, Korea
          <span class="dash">|</span> Mar 2025 â€“ Aug 2025</div>
        <ul>
          <li>Participated in â€œ<i>LIVE: Learning Interactive Visuomotor Embedding through Vision-Language Model</i>â€ as an affiliated researcher.</li>
          <li>Developed prompt learning strategies bridging off-the-shelf VLMs and LLMs.</li>
        </ul>
      </div>

      <div class="edu-item">
        <div class="role">Undergraduate Student Researcher</div>
        <div class="where"><a href="http://csg.hanyang.ac.kr/" target="_blank">CSG (Complex System Group)</a>, Hanyang University ERICA, Korea
          <span class="dash">|</span> Sep 2021 â€“ Jun 2023</div>
        <ul>
          <li>Conducted a capstone design project on neural style transfer; joined weekly lab meetings for progress sharing and feedback.</li>
          <li>Attended seminars on GNN-based modeling of COVID-19 spread and CNN-based semiconductor defect detection/analysis.</li>
        </ul>
      </div>
    </section>

    <!-- Academic Services -->
    <section id="services">
      <h2>ğŸ§‘â€âš–ï¸ Academic Services â€” Reviewer</h2>
      <ul>
        <li>IEEE Transactions on Image Processing (TIP)</li>
        <li>Engineering Applications of Artificial Intelligence (EAAI), Elsevier</li>
        <li>Expert Systems With Applications (ESWA), Elsevier</li>
      </ul>
    </section>

    <!-- Trainings & Experiences -->
    <section id="trainings">
      <h2>ğŸ‘©â€ğŸ« Trainings &amp; Experiences</h2>

      <div class="edu-item">
        <div class="role">K-Digital Training Natural Language Processing (NLP)</div>
        <div class="where"><a href="https://sites.google.com/site/jaegulchoo/" target="_blank">KAIST</a> (Prof. Jaegul Choo) &amp; <a href="https://blog.goorm.io" target="_blank">goorm Inc.</a>, Korea
          <span class="dash">|</span> Jul 2022 â€“ Nov 2022</div>
        <ul>
          <li>Completed courses in Python, Linear Algebra, Deep Learning, and Natural Language Processing.</li>
          <li>Led three team projects: (1) Text sentiment classification, (2) Korean MRC (QA), (3) Cultural backgroundâ€“aware Koreanâ€“English translator.</li>
        </ul>
        <details class="accordion">
          <summary>Accomplishments</summary>
          <div class="inner">
            <ul>
              <li><b>Project 1 â€” Sentiment Classification</b>: Parameter tuning &amp; ensemble; RoBERTa/ELECTRA ì¶”ê°€. <b>3rd / 8 teams</b>.
                <div class="pub-links">
                  <a href="https://colab.research.google.com/drive/19mFqV_DPbhZ5-0YOim7bKOPCxNYvU69z?usp=sharing" target="_blank">Colab</a>
                  <a href="https://prod-files-secure.s3.us-west-2.amazonaws.com/4c44f20d-aeb2-44e1-a6fc-1f7b3772cb8d/a10d98ee-9f40-4b1c-b66e-19a6ac6de7a8/%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%85%90%E1%84%90%E1%85%B31_%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%E1%84%8C%E1%85%A1%E1%84%85%E1%85%AD_1%E1%84%90%E1%85%B5%E1%86%B7.pdf" target="_blank">Presentation (KR)</a>
                </div>
              </li>
              <li><b>Project 2 â€” Korean MRC (QA)</b>: T5 + Levenshtein/cosine loss. <b>2nd / 8 teams</b>.
                <div class="pub-links">
                  <a href="https://prod-files-secure.s3.us-west-2.amazonaws.com/4c44f20d-aeb2-44e1-a6fc-1f7b3772cb8d/dc24a0e8-c457-4002-9588-b37d8a6a6412/%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B32_%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%E1%84%8C%E1%85%A1%E1%84%85%E1%85%AD_1%E1%84%90%E1%85%B5%E1%86%B7.pdf" target="_blank">Presentation (KR)</a>
                </div>
              </li>
              <li><b>Project 3 â€” ENâ†”KR Translator</b>: Demo &amp; slides.
                <div class="pub-links">
                  <a href="https://prod-files-secure.s3.us-west-2.amazonaws.com/4c44f20d-aeb2-44e1-a6fc-1f7b3772cb8d/99bb50e7-7f93-46c6-bce9-17d3e5d763a0/%E1%84%87%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%A8%E1%84%80%E1%85%B5_%E1%84%86%E1%85%A9%E1%84%87%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF_%E1%84%89%E1%85%B5%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%89%E1%85%A1%E1%86%BC.mp4" target="_blank">Demo (MP4)</a>
                  <a href="https://prod-files-secure.s3.us-west-2.amazonaws.com/4c44f20d-aeb2-44e1-a6fc-1f7b3772cb8d/d39447ae-e199-4fe5-9e45-53c0d81e8d57/%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B33_%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%E1%84%8C%E1%85%A1%E1%84%85%E1%85%AD_1%E1%84%90%E1%85%B5%E1%86%B7.pdf" target="_blank">Presentation (KR)</a>
                </div>
              </li>
            </ul>
          </div>
        </details>
      </div>

      <div class="edu-item">
        <div class="role">Hana Social Venture Academy</div>
        <div class="where"><a href="https://www.hanapoweron.com/intro" target="_blank">Hana Financial Group</a>, Korea
          <span class="dash">|</span> Dec 2021 â€“ Feb 2022</div>
        <ul>
          <li>Built mobile app &amp; SaaS for â€œDdaom,â€ a free counseling matching platform for teens and government-affiliated institutions.</li>
          <li>Developed a chatbot with 1,100 interactions in 2 weeks; conducted 600+ user interviews.</li>
          <li>Received a $30,000 investment proposal via VC pitching.</li>
        </ul>
        <details class="accordion">
          <summary>Accomplishments</summary>
          <div class="inner">
            <ul>
              <li>400 survey responses; 40 face-to-face interviewees in a week.</li>
              <li>2nd place in mid-term performance sharing.</li>
              <li>IR pitching videos:
                <a href="https://youtu.be/ci97u39_pwc" target="_blank">Opening</a>,
                <a href="https://youtu.be/FCync1TqXZY?si=DbwBfUTlPn0OdbvE" target="_blank">MAPP IR</a>
              </li>
              <li>Presentations (KR):
                <a href="https://prod-files-secure.s3.us-west-2.amazonaws.com/4c44f20d-aeb2-44e1-a6fc-1f7b3772cb8d/bf60620e-f8d1-4ea7-a9d9-9d0ee1e4d517/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%A1%E1%86%AB%E1%84%80%E1%85%A9%E1%86%BC%E1%84%92%E1%85%AC_%E1%84%8C%E1%85%A1%E1%84%85%E1%85%AD_MAPP.pdf" target="_blank">Mid-term</a>,
                <a href="https://prod-files-secure.s3.us-west-2.amazonaws.com/4c44f20d-aeb2-44e1-a6fc-1f7b3772cb8d/e7cc5190-6b3a-4fe5-9561-7c1eda4425c3/%E1%84%87%E1%85%A1%E1%86%AF%E1%85%91%E1%85%AD%E1%84%8C%E1%85%A1%E1%84%85%E1%85%AD_MAPP.pdf" target="_blank">Final</a>
              </li>
            </ul>
          </div>
        </details>
      </div>

      <div class="edu-item">
        <div class="role">Data Science for Machine Learning, Global Online Module</div>
        <div class="where">Department of Computer Science, <a href="https://www.gsu.edu/program/computer-science-bs/?utm_source=program-list&utm_medium=College%20of%20Arts%20&%20Sciences&utm_campaign=program-page&utm_term=Bachelor%27s," target="_blank">Georgia State University</a>, USA
          <span class="dash">|</span> Oct 2021</div>
        <ul>
          <li>Hands-on training in NumPy, SciPy, and OpenCV with team collaboration on data analysis.</li>
        </ul>
      </div>
    </section>

    <!-- Projects & Grants -->
    <section id="projects">
      <h2>ğŸ§ª Projects &amp; Grants</h2>

      <div class="edu-item">
        <div class="role">Project Leading Researcher</div>
        <div class="where"><a href="https://view.kentech.ac.kr/" target="_blank">VIEW LAB (Visual Intelligence &amp; Energy Wise Lab)</a>, KENTECH, Korea
          <span class="dash">|</span> Sep 2024 â€“ Feb 2025</div>
        <ul>
          <li>3-year grant (2024â€“2027) for â€œLIVE: Learning Interactive Visuomotor Embedding through Vision-Language Model,â€ supported by the <a href="https://www.nrf.re.kr/eng/main" target="_blank">NRF</a> of Korea.</li>
          <li>Designed &amp; executed proposal: learning temporal patterns in physics simulation frames with text-based training interfaces and contrastive imageâ€“text alignment.</li>
          <li>Collected paired data via dynamic web crawling from <a href="https://www.myphysicslab.com/" target="_blank">myphysicslab.com</a>; collaborated with its developer, Erik Neumann.</li>
        </ul>
      </div>

      <div class="edu-item">
        <div class="role">Project Affiliated Researcher</div>
        <div class="where"><a href="https://view.kentech.ac.kr/" target="_blank">VIEW LAB (Visual Intelligence &amp; Energy Wise Lab)</a>, KENTECH, Korea
          <span class="dash">|</span> Mar 2023 â€“ Aug 2024</div>
        <ul>
          <li><a href="https://www.nrf.re.kr/eng/main" target="_blank">NRF</a> grant: Generalization &amp; Robustness of Learning-Based 3D Visual Perception (MSIT).</li>
          <li><a href="http://iitp.kr/en/main.it" target="_blank">IITP</a> grant: Innovative Human Resource Development for Local Intellectualization (MSIT).</li>
          <li><a href="https://www.kiat.or.kr/eng/user/main.do" target="_blank">KIAT</a> grant: funded by MOTIE, Korea.</li>
        </ul>
      </div>
    </section>

    <!-- Awards -->
    <section id="awards">
      <h2>ğŸ† Awards</h2>

      <div class="edu-item">
        <div class="role">Capstone Design Contest â€” Scientific Technical Award (2nd place)</div>
        <div class="where">Hanyang University (Seoul &amp; ERICA), Korea
          <span class="dash">|</span> May 2022</div>
        <ul>
          <li>Neural Style Transfer project using a fine-tuned ResNet18 (ImageNet) to improve style classification by 4.6% and enhance stylization quality.</li>
          <li>Poster (KR): <a href="https://prod-files-secure.s3.us-west-2.amazonaws.com/4c44f20d-aeb2-44e1-a6fc-1f7b3772cb8d/ce3b91c0-3ed5-41ad-816d-fea561747bd0/%E1%84%8F%E1%85%A2%E1%86%B8%E1%84%89%E1%85%B3%E1%84%90%E1%85%A9%E1%86%AB_%E1%84%91%E1%85%A9%E1%84%89%E1%85%B3%E1%85%B3_%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%A1%E1%84%92%E1%85%A7%E1%86%AB.pdf" target="_blank">PDF</a></li>
        </ul>
      </div>

      <div class="edu-item">
        <div class="role">Software Hackathon â€” Bronze Award (3rd place)</div>
        <div class="where">Hanyang University ERICA, Korea
          <span class="dash">|</span> Nov 2019</div>
        <ul>
          <li>â€œLunchbox of Loveâ€ â€” social impact app prototype for surplus food delivery to seniors via retiree couriers.</li>
        </ul>
      </div>
    </section>

    <!-- Languages -->
    <section id="languages">
      <h2>ğŸ“¢ Languages</h2>
      <ul>
        <li>ğŸ‡°ğŸ‡· <b>Korean</b> (Native)</li>
        <li>ğŸ‡ºğŸ‡¸ <b>English</b> â€” TOEFL iBT: <b>101/120</b> (R27, L26, S24, W24); TOEIC: <b>855/990</b> (R420, L435)</li>
        <li>ğŸ‡ªğŸ‡¸ <b>Spanish</b> (A1) â€” <a href="https://rm.coe.int/CoERMPublicCommonSearchServices/DisplayDCTMContent?documentId=090000168045bb52" target="_blank">CEFR</a></li>
        <li>ğŸ‡¯ğŸ‡µ <b>Japanese</b> (A1) â€” <a href="https://rm.coe.int/CoERMPublicCommonSearchServices/DisplayDCTMContent?documentId=090000168045bb52" target="_blank">CEFR</a></li>
      </ul>
    </section>

    <!-- Skills -->
    <section id="skills">
      <h2>ğŸ¨ Skills</h2>
      <ul>
        <li><b>Deep Learning &amp; ML</b>: Python, PyTorch, Bash, NumPy, OpenCV, scikit-learn, Hugging Face (transformers, diffusers), LMs (BERT, T5, LLaMA, GPT), VLMs (LLaVA, BLIP, CLIP)</li>
        <li><b>App/Web</b>: MySQL, Android Studio (Java), HTML/CSS, Selenium (dynamic crawling), KakaoTalk chatbot</li>
        <li><b>UI/UX &amp; Illustration</b>: Procreate, Figma, Adobe Illustrator, Adobe XD</li>
        <li><b>Soft skills</b>: Problem-solving, People insight, Constructive discussion, Team player, Active listening</li>
      </ul>
    </section>

    <!-- Free Time -->
    <section id="free-time">
      <h2>â³ Free time interests</h2>
      <ul>
        <li>Yoga (Hatha, Vinyasa, Ashtanga) â†’ IG: @yoga._hyeon</li>
        <li>Reading books â†’ IG: @sat_bookclub</li>
        <li>Surf &amp; Snowboarding</li>
        <li>Playing piano</li>
      </ul>
    </section>
  </main>

  <!-- Footer -->
  <footer>
    <p><em>* Unauthorized use or misuse of personal information is strictly prohibited. *</em></p>
    <p>I certify that this vitae is accurate and complete. â€” Sep. 16th, 2025 (latest update)</p>
  </footer>

  <script>
    // TOC toggle (mobile)
    const toc = document.getElementById('toc');
    const toggleBtn = document.querySelector('.toc-toggle');
    toggleBtn.addEventListener('click', () => {
      const open = toc.classList.toggle('open');
      toggleBtn.setAttribute('aria-expanded', open ? 'true' : 'false');
    });

    // Scroll highlight
    const links = Array.from(toc.querySelectorAll('a[href^="#"]'));
    const targets = links.map(a => document.querySelector(a.getAttribute('href'))).filter(Boolean);
    const obs = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        const id = '#' + entry.target.id;
        const link = links.find(a => a.getAttribute('href') === id);
        if (link) {
          if (entry.isIntersecting) {
            links.forEach(l => l.classList.remove('active'));
            link.classList.add('active');
          }
        }
      });
    }, { rootMargin: '-40% 0px -55% 0px', threshold: 0.01 });
    targets.forEach(t => obs.observe(t));
  </script>
</body>
</html>
